{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Chargement & configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'src')))\n",
    "\n",
    "from requirements import *\n",
    "from src import data_preprocessing as dp\n",
    "from src import model_training as mt\n",
    "from src import evaluate as ev\n",
    "from src import utils\n",
    "\n",
    "import mlflow\n",
    "mlflow.set_experiment(\"Sentiment Analysis Project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - Affichage de la structure dossier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.afficher_structure_dossier(\"..\", max_niveaux = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/tweets.csv\"\n",
    "if os.path.exists(data_path):\n",
    "    tweets = pd.read_csv(data_path, encoding=\"ISO-8859-1\")\n",
    "    print(\"✅ Dataset chargé avec succès !\")\n",
    "else:\n",
    "    print(\"❌ Le fichier tweets.csv est introuvable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Exploration & nettoyage\n",
    "## 2.1 - Nettoyage rapide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets.info())\n",
    "print(tweets['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Nettoyage avancé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_cleaned = dp.preprocess_tweets_parallel(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Vader scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_scores = dp.compute_vader_scores(tweets_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Vectorisation des tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bow, X_tfidf, X_fasttext, X_use = dp.vectorize_tweets(tweets_cleaned['text'], tweets_cleaned['text'].sample(frac = 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Modélisation Classique (TF-IDF + Régression Logistique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf_train, X_tfidf_test, y_train, y_test = train_test_split(\n",
    "    X_tfidf, tweets_cleaned['label'], test_size = 0.2, random_state = 70, stratify=tweets_cleaned['label']\n",
    ")\n",
    "log_reg_model = mt.train_logistic_regression_with_cv(X_tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Modèles Avancés (Random Forest / LightGBM / LSTM)\n",
    "## 6.1 - FastText + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ft_train, X_ft_test, y_train, y_test = train_test_split(\n",
    "    X_fasttext, tweets_cleaned['label'], test_size = 0.2, random_state = 70, stratify = tweets_cleaned['label']\n",
    ")\n",
    "rf_model = mt.train_random_forest(X_ft_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 - FastText + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model, (X_ft_test_reshaped, y_ft_test), history = mt.train_lstm_model(X_fasttext, tweets_cleaned['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 - USE + LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_use_train, X_use_test, y_train, y_test = train_test_split(\n",
    "    X_use, tweets_cleaned['label'], test_size = 0.2, random_state = 70, stratify = tweets_cleaned['label']\n",
    ")\n",
    "lgbm_model = mt.train_lightgbm(X_use_train, y_train, X_use_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 - DistilBERT\n",
    "### 6.4.1 - Préparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = dp.prepare_distilbert_dataset(tweets_cleaned)\n",
    "tokenized = dp.tokenize_distilbert_dataset(df_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 - Fine-tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, trainer, _ = mt.train_distilbert_model(tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert_acc, distilbert_f1 = ev.evaluate_distilbert_model(model, tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 - Comparaison finale des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "    'logreg': log_reg_model,\n",
    "    'rf': rf_model,\n",
    "    'lstm': lstm_model,\n",
    "    'lgbm': lgbm_model,\n",
    "    'distilbert_metrics': {\n",
    "        'accuracy': distilbert_acc,\n",
    "        'f1': distilbert_f1\n",
    "    }\n",
    "}\n",
    "\n",
    "datasets_dict = {\n",
    "    'tfidf': {'X_test': X_tfidf_test, 'y_test': y_test},\n",
    "    'fasttext': {'X_test': X_ft_test, 'y_test': y_test},\n",
    "    'lstm': (X_ft_test_reshaped, y_ft_test),\n",
    "    'use': {'X_test': X_use_test, 'y_test': y_test}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = ev.get_all_model_scores(models_dict, datasets_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 - Tracking MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    # entraînement modèle, log params & metrics\n",
    "    mlflow.log_param(\"model\", \"Logistic Regression\")\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_p7_MLOps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
